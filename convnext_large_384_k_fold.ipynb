{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T07:48:15.691457Z",
     "start_time": "2025-09-15T07:48:15.672164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T07:50:50.956315Z",
     "start_time": "2025-09-15T07:50:49.049339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Literal, Union\n",
    "\n",
    "import math\n",
    "from adamp import AdamP\n",
    "from torchvision.transforms.v2.functional import to_pil_image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import asyncio\n",
    "import tqdm\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "\n",
    "import src.data\n",
    "import lib\n",
    "\n",
    "# from lib import predict_siglip\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T07:52:03.723387Z",
     "start_time": "2025-09-15T07:52:03.708553Z"
    }
   },
   "cell_type": "code",
   "source": "type(src.data.train_features.filepath)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model instantiation"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "restore_from_checkpoint: Union[int, bool] = True\n",
    "\n",
    "model_id = \"facebook/convnext-large-384-22k-1k\"  # FixRes вариант\n",
    "model_preprocessor = AutoImageProcessor.from_pretrained(model_id)  # даст resize/normalize, mean/std/size\n",
    "\n",
    "optimizer = None\n",
    "\n",
    "# upcoming training epoch\n",
    "epoch = 0\n",
    "\n",
    "if restore_from_checkpoint == True or isinstance(restore_from_checkpoint, int) and not isinstance(restore_from_checkpoint, bool):\n",
    "    if restore_from_checkpoint == True:\n",
    "        epochs = lib.model_checkpoints(f'./models_convnext_large_384/checkpoint_*.pth')\n",
    "\n",
    "        if len(epochs) == 0:\n",
    "            print('no models found')\n",
    "            raise ValueError('No model found')\n",
    "\n",
    "        checkpoint_num = epochs[ 0 ]\n",
    "    else:\n",
    "        checkpoint_num = restore_from_checkpoint\n",
    "\n",
    "    print(f'Loading model from epoch { checkpoint_num }')\n",
    "\n",
    "    checkpoint = torch.load(f'./models_convnext_large_384/checkpoint_{ checkpoint_num }.pth', weights_only=False)\n",
    "\n",
    "    model = checkpoint['model']\n",
    "    optimizer = checkpoint['optimizer']\n",
    "\n",
    "    epoch = model.epoch + 1\n",
    "else:\n",
    "    # Веса энкодера + НОВАЯ голова классификации (num_labels=2):\n",
    "    model = AutoModelForImageClassification.from_pretrained(\n",
    "        model_id,\n",
    "        num_labels=len(data.species_labels),\n",
    "        ignore_mismatched_sizes=True,  # создаст новую голову нужного размера\n",
    "    )\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "\n",
    "    model.tracking_loss = []\n",
    "    model.tracking_loss_val = []\n",
    "    model.tracking_accuracy = []\n",
    "    model.tracking_val_probs = []\n",
    "    # the last epoch we finished training on\n",
    "    model.epoch = None\n",
    "\n",
    "tracking_loss = model.tracking_loss\n",
    "tracking_loss_val = model.tracking_loss_val\n",
    "tracking_accuracy = model.tracking_accuracy\n",
    "tracking_val_probs = model.tracking_val_probs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_ds = lib.ImageDatasetSigLip2(data.x_train, data.y_train, processor=model_preprocessor, learning=True)\n",
    "val_ds   = lib.ImageDatasetSigLip2(data.x_eval, data.y_eval, processor=model_preprocessor, learning=False)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=192, shuffle=True, num_workers=6)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=128, shuffle=False, num_workers=6)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Optimizer"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if optimizer is None:\n",
    "    optimizer = AdamP([\n",
    "        {'name': \"encoder\", \"params\": [],  \"lr\": 1e-4, \"weight_decay\": 0.05},\n",
    "        {'name': \"classifier\", \"params\": [], \"lr\": 1e-3, \"weight_decay\": 0.01}\n",
    "    ])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Freezing"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# unfreezing: Literal['classifier_only', 'classifier_and_encoder', 'all'] = 'classifier_and_encoder'\n",
    "# L = 6  # начните с 2–4; при достаточном VRAM можно 6–8\n",
    "#\n",
    "# # C) Параметрические группы с «ступенчатым» LR: у головы LR выше, у энкодера ниже\n",
    "# head_params = []\n",
    "# enc_params  = []\n",
    "#\n",
    "# if unfreezing == 'classifier_only':\n",
    "#     # 2) Заморозим всё, кроме головы (линейный пробинг)\n",
    "#     for name, p in model.named_parameters():\n",
    "#         p.requires_grad = \"classifier\" in name  # у HF-классификаторов голова обычно называется \"classifier\"\n",
    "#\n",
    "#         if \"classifier\" in name:\n",
    "#             head_params.append(p)\n",
    "#\n",
    "# elif unfreezing == 'classifier_and_encoder':\n",
    "#     # A) Сначала всё заморозим\n",
    "#     for p in model.parameters():\n",
    "#         p.requires_grad = False\n",
    "#     for name, p in model.named_parameters():\n",
    "#         if \"classifier\" in name:\n",
    "#             p.requires_grad = True  # голова остаётся обучаемой\n",
    "#             head_params.append(p)\n",
    "#\n",
    "#     # B) Разморозим последние L блоков визуального энкодера\n",
    "#     layers = model.vision_model.encoder.layers   # ModuleList\n",
    "#     for block in layers[-L:]:\n",
    "#         for p in block.parameters():\n",
    "#             p.requires_grad = True\n",
    "#             enc_params.append(p)\n",
    "# elif unfreezing == 'all':\n",
    "#     for p in model.parameters():\n",
    "#         p.requires_grad = True\n",
    "# else:\n",
    "#     raise ValueError(f\"Unknown unfreezing mode: {unfreezing}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "optimizer.param_groups = []\n",
    "\n",
    "optimizer.add_param_group({'name': \"encoder\", \"params\": enc_params,  \"lr\": 1e-5, \"weight_decay\": 0.01})\n",
    "optimizer.add_param_group({'name': \"classifier\", \"params\": head_params, \"lr\": 2e-5, \"weight_decay\": 0.01})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Loss (possibly with weights)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# criterion = lib.sce_loss"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Cutmix + mixup"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torchvision.transforms import v2\n",
    "\n",
    "use_cutmix_mixup = True\n",
    "\n",
    "cutmix = v2.CutMix(alpha=0.3, num_classes=len(data.species_labels))\n",
    "mixup = v2.MixUp(alpha=0.3, num_classes=len(data.species_labels))\n",
    "cutmix_or_mixup = v2.RandomChoice([cutmix, mixup])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# steps_per_epoch = len(train_loader)\n",
    "#\n",
    "# def scheduler(step):\n",
    "#\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "FOLDS_NUM = 5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Loop"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_epochs = 15\n",
    "\n",
    "for fold in range(FOLDS_NUM):\n",
    "    print(f\"Fold {fold}\")\n",
    "\n",
    "\n",
    "\n",
    "for cur_epoch in range(epoch, epoch + num_epochs):\n",
    "    await asyncio.sleep(0)\n",
    "\n",
    "    if stop_flag['value'] == True:\n",
    "        break\n",
    "\n",
    "    print(f\"Starting epoch {cur_epoch}\")\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    loss_acc = 0\n",
    "    count = 0\n",
    "\n",
    "    for idx, batch in tqdm.tqdm(enumerate(train_loader), total=len(train_loader), desc='Training'):\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        images, labels = batch[\"pixel_values\"].to(torch.device(\"cuda\")), batch[\"labels\"].to(torch.device(\"cuda\"))\n",
    "\n",
    "        if use_cutmix_mixup:\n",
    "            images, labels = cutmix_or_mixup(images, labels)\n",
    "\n",
    "        refined_labels_df = model(images)              # logits: (B, 2)\n",
    "        loss = criterion(refined_labels_df.logits, labels)\n",
    "\n",
    "        c = batch['pixel_values'].size(0)\n",
    "        loss_acc += loss.item() * c\n",
    "        count += c\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    tracking_loss.append(loss_acc / count)\n",
    "\n",
    "    # валидация\n",
    "    model.eval()\n",
    "\n",
    "    probs, loss_acc = predict_siglip(\n",
    "        model, val_loader, accumulate_probs=True, accumulate_loss=True, desc='Validation', columns=data.species_labels, criterion=criterion\n",
    "    )\n",
    "    tracking_val_probs.append(probs)\n",
    "    tracking_loss_val.append(loss_acc)\n",
    "\n",
    "    eval_predictions = probs.idxmax(axis=1)\n",
    "    eval_true = data.y_eval.idxmax(axis=1)\n",
    "    correct = (eval_predictions == eval_true).sum()\n",
    "    accuracy = correct / len(eval_predictions)\n",
    "    tracking_accuracy.append(accuracy.item())\n",
    "\n",
    "    model.epoch = cur_epoch\n",
    "    lib.save_model(model, optimizer, f\"./models_convnext_large_384/checkpoint_{str(cur_epoch).rjust(2, \"0\")}.pth\")\n",
    "\n",
    "    epoch = cur_epoch + 1\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training progress"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pd.DataFrame({'tracking_loss' : tracking_loss, 'tracking_loss_val' : tracking_loss_val, 'tracking_accuracy' : tracking_accuracy }, index=range(len(tracking_accuracy)))",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "epochs_train = list(range(len(tracking_loss)))\n",
    "epochs_val = list(range(len(tracking_loss_val)))\n",
    "\n",
    "line1, = ax.plot(epochs_train, tracking_loss, label=\"Train loss\")\n",
    "line2, = ax.plot(epochs_val, tracking_loss_val, label=\"Validation loss\")\n",
    "\n",
    "ax.set_xlabel(\"Epoch (index)\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.legend(loc=\"best\", handles=[line1, line2])\n",
    "\n",
    "ax.set_xticks(epochs_train)\n",
    "\n",
    "ax.grid(True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "epochs_accuracy = list(range(len(tracking_accuracy)))\n",
    "\n",
    "line1, = ax.plot(epochs_accuracy, tracking_accuracy, label=\"Accuracy\", color=\"red\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "\n",
    "ax.legend(loc=\"best\", handles=[line1])\n",
    "\n",
    "ax.set_xticks(epochs_train)\n",
    "\n",
    "ax.grid(True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Validation"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "## search for optimal temperature",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# temp_acc = {}",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# for key in sorted(temp_acc.keys()):\n",
    "#     print(f'T={key:.5f}: {temp_acc[key]:.5f}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# import numpy as np\n",
    "#\n",
    "# for t in np.arange(0.785, 0.82, 0.0125):\n",
    "#     _, loss = lib.predict_siglip(model, val_loader, accumulate_loss=True, accumulate_probs=False, criterion=criterion, T=t, desc='Searching', columns=data.species_labels)\n",
    "#\n",
    "#     print(f\"T={t:.5f}: {loss:.4f}\")\n",
    "#\n",
    "#     temp_acc[t] = loss"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "eval_preds_df = tracking_val_probs[-1]\n",
    "\n",
    "# eval_preds_df_ten_crop = lib.predict_siglip_ten_crop(model, val_loader, T=1, desc='Predicting', columns=data.species_labels)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "eval_preds_df.head()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# eval_preds_df_ten_crop.head()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"True labels (training):\")\n",
    "data.y_train.idxmax(axis=1).value_counts(normalize=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Predicted labels (eval):\")\n",
    "eval_preds_df.idxmax(axis=1).value_counts(normalize=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"True labels (eval):\")\n",
    "data.y_eval.idxmax(axis=1).value_counts(normalize=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "eval_predictions = eval_preds_df.idxmax(axis=1)\n",
    "# eval_predictions_ten_crop = eval_preds_df_ten_crop.idxmax(axis=1)\n",
    "eval_true = data.y_eval.idxmax(axis=1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# (eval_predictions_ten_crop != eval_predictions).sum()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f'Accuracy plain: { (eval_predictions == eval_true).mean() }')\n",
    "# print(f'Accuracy ten crop: { (eval_predictions_ten_crop == eval_true).mean() }')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Predictions vs actual"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "eval_preds = eval_preds_df.copy()\n",
    "\n",
    "eval_preds[ 'cls' ] = eval_preds_df.idxmax(axis=1)\n",
    "eval_preds[ 'cls_true' ] = data.y_eval.idxmax(axis=1)\n",
    "\n",
    "# eval_preds[(eval_preds[ 'cls' ] == 'blank') & (eval_preds[ 'cls_true' ] == 'leopard')]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data.species_labels",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import math\n",
    "from itertools import zip_longest\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "# %matplotlib notebook\n",
    "# %matplotlib widget\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "random_state = 41111\n",
    "\n",
    "# rows = eval_preds[(eval_preds[ 'cls' ] == 'blank') & (eval_preds[ 'cls_true' ] == 'leopard')]\n",
    "rows = eval_preds[(eval_preds[ 'cls' ] == 'blank') & (eval_preds[ 'cls_true' ] == 'leopard')]\n",
    "\n",
    "rows = rows.sample(frac=0.2, random_state=random_state)\n",
    "\n",
    "n_cols = 3\n",
    "n_rows = math.ceil(len(rows) / n_cols)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(18, 35))\n",
    "\n",
    "# fig.canvas.layout.width = '100%'   # ширину займёт вся ячейка\n",
    "# Высоту ipywidgets не умеют «auto», укажи соотношение/высоту:\n",
    "# fig.set_figheight(fig.get_figwidth() * 0.6)\n",
    "\n",
    "invert = v2.RandomInvert(p=1)\n",
    "\n",
    "# iterate through each species\n",
    "print(f'Total rows: {len(rows)}')\n",
    "\n",
    "clahe = lib.LabCLAHE()\n",
    "\n",
    "for row, ax in zip_longest(list(rows.iterrows()), axes.flatten()):\n",
    "    if row is None:\n",
    "        if ax is not None:\n",
    "            ax.remove()\n",
    "        continue\n",
    "    if ax is None:\n",
    "        break\n",
    "    img = Image.open('data/train_features/' + row[0] + '.jpg')\n",
    "    ax.imshow(to_pil_image(clahe(clahe((img)))))\n",
    "    ax.set_title(f\"{row[1].name} \")\n",
    "\n",
    "fig.tight_layout()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Confusion matrix"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "cm = ConfusionMatrixDisplay.from_predictions(\n",
    "    data.y_eval.idxmax(axis=1),\n",
    "    eval_preds_df.idxmax(axis=1),\n",
    "    ax=ax,\n",
    "    xticks_rotation=30,\n",
    "    colorbar=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create submission"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_dataset = lib.ImageDatasetSigLip2(data.test_features, processor=model_preprocessor, learning=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=6)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "submission_df, _ = predict_siglip(model, test_dataloader, T=1, columns=data.species_labels)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "submission_format = pd.read_csv(\"data/submission_format.csv\", index_col=\"id\")\n",
    "\n",
    "assert all(submission_df.index == submission_format.index)\n",
    "assert all(submission_df.columns == submission_format.columns)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "submission_df.to_csv(\"submission.csv\")",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}